#!/usr/bin/env python3
"""
Import glucose data from LibreView CSV export into health database.

LibreView CSV format:
- Row 1: Metadata (Generated on, Generated by)
- Row 2: Column headers
- Row 3+: Data rows

Record Types:
- 0: Historic Glucose (passive, every 15 min)
- 1: Scan Glucose (manual scan)
- 5: Food/Carbs logged
- 6: Notes/Other

Usage:
    python import_libre.py path/to/glucose_export.csv
    python import_libre.py path/to/glucose_export.csv --dry-run
"""

import argparse
import sys
from pathlib import Path
from datetime import datetime
import duckdb

from config import get_db_path


def parse_libre_timestamp(ts_str: str) -> datetime:
    """Parse LibreView timestamp format: MM-DD-YYYY HH:MM"""
    return datetime.strptime(ts_str, "%m-%d-%Y %H:%M")


def import_libre_csv(csv_path: Path, dry_run: bool = False) -> dict:
    """
    Import LibreView glucose CSV into DuckDB.
    
    Returns dict with import statistics.
    """
    if not csv_path.exists():
        raise FileNotFoundError(f"CSV not found: {csv_path}")
    
    filename = csv_path.name
    db_path = get_db_path()
    conn = duckdb.connect(str(db_path))
    
    # Check if already imported
    existing = conn.execute(
        "SELECT import_id FROM imports WHERE filename = ?",
        [filename]
    ).fetchone()
    
    if existing:
        print(f"‚è≠Ô∏è  Already imported: {filename}")
        conn.close()
        return {"status": "skipped", "reason": "already_imported"}
    
    # Read CSV, skip first metadata row
    print(f"üìñ Reading {csv_path}...")
    
    with open(csv_path, 'r') as f:
        lines = f.readlines()
    
    # Parse header (row 2, index 1)
    header = lines[1].strip().split(',')
    col_idx = {name: i for i, name in enumerate(header)}
    
    timestamp_col = col_idx.get('Device Timestamp')
    record_type_col = col_idx.get('Record Type')
    historic_glucose_col = col_idx.get('Historic Glucose mg/dL')
    scan_glucose_col = col_idx.get('Scan Glucose mg/dL')
    device_col = col_idx.get('Device')
    
    if timestamp_col is None or record_type_col is None:
        raise ValueError(f"Missing required columns. Found: {header}")
    
    # Parse data rows
    readings = []
    skipped = 0
    errors = 0
    
    for i, line in enumerate(lines[2:], start=3):
        try:
            cols = line.strip().split(',')
            
            if len(cols) < max(timestamp_col, record_type_col, 
                              historic_glucose_col or 0, scan_glucose_col or 0) + 1:
                skipped += 1
                continue
            
            record_type = cols[record_type_col].strip()
            
            # Only import glucose readings (type 0 = historic, type 1 = scan)
            if record_type not in ('0', '1'):
                skipped += 1
                continue
            
            timestamp_str = cols[timestamp_col].strip()
            if not timestamp_str:
                skipped += 1
                continue
            
            timestamp = parse_libre_timestamp(timestamp_str)
            
            if record_type == '0':
                glucose_val = cols[historic_glucose_col].strip() if historic_glucose_col else ''
                metric = "Glucose (Historic)"
            else:
                glucose_val = cols[scan_glucose_col].strip() if scan_glucose_col else ''
                metric = "Glucose (Scan)"
            
            if not glucose_val:
                skipped += 1
                continue
            
            try:
                value = float(glucose_val)
            except ValueError:
                skipped += 1
                continue
            
            readings.append({
                'timestamp': timestamp,
                'metric': metric,
                'value': value,
                'unit': 'mg/dL',
                'source': 'libre',
            })
            
        except Exception as e:
            errors += 1
            if errors <= 5:
                print(f"‚ö†Ô∏è  Row {i}: {e}")
    
    print(f"üìä Parsed {len(readings):,} glucose readings ({skipped:,} skipped, {errors} errors)")
    
    if dry_run:
        print("üèÉ Dry run ‚Äî no changes made")
        conn.close()
        return {
            "status": "dry_run",
            "readings_parsed": len(readings),
            "skipped": skipped,
            "errors": errors
        }
    
    # Insert readings (with deduplication)
    inserted = 0
    duplicates = 0
    
    for r in readings:
        try:
            conn.execute("""
                INSERT INTO readings (timestamp, metric, value, unit, source)
                VALUES (?, ?, ?, ?, ?)
                ON CONFLICT (timestamp, metric, source) DO NOTHING
            """, [r['timestamp'], r['metric'], r['value'], r['unit'], r['source']])
            inserted += 1
        except duckdb.ConstraintException:
            duplicates += 1
    
    # Log the import
    conn.execute("""
        INSERT INTO imports (filename, imported_at, rows_added, source)
        VALUES (?, CURRENT_TIMESTAMP, ?, 'libre')
    """, [filename, inserted])
    
    conn.commit()
    conn.close()
    
    print(f"‚úÖ Imported {inserted:,} readings from {filename}")
    
    return {
        "status": "success",
        "filename": filename,
        "readings_parsed": len(readings),
        "inserted": inserted,
        "duplicates": duplicates,
        "skipped": skipped,
        "errors": errors
    }


def main():
    parser = argparse.ArgumentParser(description="Import LibreView glucose CSV")
    parser.add_argument("csv_path", type=Path, help="Path to LibreView CSV export")
    parser.add_argument("--dry-run", action="store_true", help="Parse only, don't import")
    
    args = parser.parse_args()
    
    try:
        result = import_libre_csv(args.csv_path, dry_run=args.dry_run)
        print(f"\nüìã Result: {result}")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
